# YOLO物体検出アプリケーション 要件定義

このプロジェクトは、YOLO（You Only Look Once）物体検出モデルのためのアノテーションと推論を行うWebアプリケーションです。

## プロジェクトの目的

YOLOモデルのアノテーションから推論までを一貫して管理できるWebアプリケーションを構築すること。

## 技術スタック

- **フレームワーク**: Django（Python Webフレームワーク）
- **機械学習**: YOLOv9モデル（物体検出用の深層学習モデル）
- **学習環境**: Google Colab（クラウドベースのJupyterノートブック環境）
- **コンテナ**: Docker（開発・本番環境の両方で使用）
- **認証**: ログイン機能は不要（認証なしでアクセス可能）

### 既存リソース

- `yolov9/` フォルダー: 動作確認済みのYOLOv9実装が含まれています
  - このフォルダー内の不要なファイルやテストファイルを整理してください
  - **推論の実行手順**:
    1. 推論したい画像を `yolov9/dataset/images/inference` フォルダーに配置します
    2. `yolov9/yolo/config` フォルダー内の `general.yml` と `task/inference.yml` の設定を行います(GPUがない場合はデバイスの設定も変える必要あり)
    3. 学習済み重みファイルを `yolov9/weights/best.pt` として配置します
    4. `python yolo/inference.py` を実行します
    5. 推論結果の画像（検出されたクラス名と信頼度（%）が表示された画像）が `yolov9/runs/inference/results/` フォルダーに出力されます

## 主な機能とワークフロー
1. データインポート機能
   - YOLO学習用の画像データセットをアプリケーションにインポート

2. アノテーション機能
   - インポートした画像に対して、物体の位置情報（バウンディングボックス）とクラスラベルを付与
   - アノテーションとは、画像内の物体に「どこに何があるか」を手動でマーキングする作業

3. データエクスポート機能
   - アノテーション済みデータセットをYOLO学習用フォーマット（YOLO形式のテキストファイルと画像のセット）でエクスポート

4. モデル学習機能
   - エクスポートしたデータセットをGoogle Colab上で使用してYOLOモデルを学習
   - 学習が完了すると、物体検出が可能な学習済みモデルファイル（.pt形式など）が生成される

5. モデルインポート機能
   - Colabで学習したモデルファイルをアプリケーションにインポート

6. 推論機能
   - インポートした学習済みモデルを使用して、新しい画像に対して物体検出の推論（予測）を実行
   - 推論結果として、検出された物体の位置とクラスが表示される

## 機能要件

### 画面1: train用のアノテーション作成画面

#### 1.1 画像インポート機能
- **方法**: ドラッグ&ドロップまたはファイル選択ダイアログ
- **対応形式**: 一般的な画像形式（jpg, png, jpeg等）
- **動作**: インポートした画像は即座に画面に表示される
- **複数選択**: 複数画像の一括インポートに対応

#### 1.2 画像表示エリア
- **配置**: メインエリア
- **機能**: 
  - インポートした画像を一覧表示（アノテーション作業がしやすい適切なサイズで表示）
  - 画像上でマウス操作による矩形描画が可能

#### 1.3 クラス管理パネル（左側）
- **配置**: 画面左側に固定サイドバー
- **機能**:
  - クラス一覧の表示
  - 「追加」ボタンで新しいクラスを追加（クラス名・色を入力）
  - クラスをクリックして選択状態にする（選択中のクラスは視覚的に区別）
  - 選択したクラスがアノテーションに適用される

#### 1.4 アノテーション機能
- **操作フロー**:
  1. 左側パネルでクラスを選択
  2. 画像上でマウスドラッグして矩形（バウンディングボックス）を描画
  3. 矩形が描画されると、選択中のクラスが自動的に割り当てられる
- **表示**: 矩形は色分けして表示（クラスごとに異なる色）
- **編集**: 既存の矩形を選択して削除または修正可能

#### 1.5 エクスポート機能
- **ボタン**: 「完了」ボタンを画面に配置
- **確認画面**: モーダルで「エクスポートしてもいいですか？」と確認し、「エクスポート」ボタンで出力開始
- **ダウンロード方法**: ブラウザのダウンロード機能を使用してダウンロード
- **保存先**: ブラウザのデフォルトダウンロードフォルダ（通常はユーザーのダウンロードフォルダ）
- **出力形式**: `train.zip` ファイルとしてダウンロード（展開すると以下の構造）
  ```
  train/
  ├── images/
  │   ├── image001.jpg
  │   ├── image002.jpg
  │   └── ...
  └── labels/
      ├── image001.txt
      ├── image002.txt
      └── ...
  ```
- **出力内容**:
  - **imagesフォルダ**: アノテーション対象の画像ファイル
  - **labelsフォルダ**: YOLO形式のテキストファイル（各画像に対応する.txtファイル）
    - **ファイル名**: `画像名.txt`（例: `image001.jpg` → `image001.txt`）
    - **フォーマット**: 正規化座標で以下の形式
      ```
      class_id center_x center_y width height
      ```

### 画面2: val用のアノテーション作成画面

画面1と同様の機能を提供しますが、エクスポート先が異なります。

#### 2.5 エクスポート機能（画面2）

- **ボタン**: 「完了」ボタンを画面に配置
- **確認画面**: モーダルで「エクスポートしてもいいですか？」と確認し、「エクスポート」ボタンで出力開始
- **ダウンロード方法**: ブラウザのダウンロード機能を使用してダウンロード
- **保存先**: ブラウザのデフォルトダウンロードフォルダ（通常はユーザーのダウンロードフォルダ）
- **出力形式**: `val.zip` ファイルとしてダウンロード（展開すると以下の構造）
  ```
  val/
  ├── images/
  │   ├── image001.jpg
  │   ├── image002.jpg
  │   └── ...
  └── labels/
      ├── image001.txt
      ├── image002.txt
      └── ...
  ```
- **出力内容**:
  - **imagesフォルダ**: アノテーション対象の画像ファイル
  - **labelsフォルダ**: YOLO形式のテキストファイル（各画像に対応する.txtファイル）
    - **ファイル名**: `画像名.txt`（例: `image001.jpg` → `image001.txt`）
    - **フォーマット**: 正規化座標で以下の形式
      ```
      class_id center_x center_y width height
      ```

### 画面3: 推論実行画面

#### 3.1 モデルインポート機能
- **対象**: Google Colabで学習した学習済み重みファイル（.pt形式）
- **方法**: ファイル選択ダイアログまたはドラッグ&ドロップ

#### 3.2 推論画像インポート機能
- **方法**: ドラッグ&ドロップまたはファイル選択ダイアログ
- **対応**: 単一画像または複数画像
- **表示**: インポートした画像をプレビュー表示

#### 3.3 推論設定機能
- **配置**: 推論実行前に設定可能なパネルまたはフォーム
- **設定項目**:
  - **img_size**: 推論時の入力画像サイズ（ピクセル単位、例: 640）
    - 画像を推論モデルに入力する際のリサイズサイズを指定
    - デフォルト値: 640
  - **num_workers (cpu_num)**: CPUワーカー数（並列処理の数）
    - 推論処理を並列実行する際のCPUスレッド数を指定
    - デフォルト値: 4（または利用可能なCPUコア数）
  - **min_confidence**: 最小信頼度（検出結果の信頼度の閾値）
    - 検出結果の信頼度がこの値以上のもののみを表示
    - 範囲: 0.0-1.0
    - デフォルト値: 0.25
  - **min_iou**: 最小IoU（Non-Maximum SuppressionのIoU閾値）
    - 重複する検出結果を統合する際のIoU（Intersection over Union）閾値
    - 範囲: 0.0-1.0
    - デフォルト値: 0.45
  - **max_bbox**: 最大バウンディングボックス数（1画像あたりの最大検出数）
    - 1枚の画像に対して最大何個の物体を検出するかを指定
    - デフォルト値: 300
- **UI**: 各設定項目は数値入力フィールドで設定可能（スライダーやドロップダウンも可）

#### 3.4 推論実行機能
- **ボタン**: 「推論開始」ボタン
- **処理**:
  1. インポート済みの学習済みモデルを読み込む
  2. 推論設定（img_size、num_workers、min_confidence、min_iou、max_bbox）を適用
  3. 推論画像に対して物体検出を実行
  4. 検出結果を画像上に描画（バウンディングボックス + クラス名 + 信頼度スコア）

#### 3.5 結果表示機能
- **表示内容**:
  - 検出された物体のバウンディングボックス
  - クラス名
  - 信頼度スコア（0.0-1.0）
- **保存**: 推論結果画像を保存できる機能

## データフロー

### アノテーション → 学習用データセット

```
画像インポート → アノテーション作成 → エクスポート
```

### 推論フロー

```
学習済みモデル(.pt)インポート → 推論画像インポート → 推論設定 → 推論実行 → 結果表示
```

## 実装の優先順位

1. **Phase 1**: 基本的なDjangoプロジェクトセットアップ + Docker環境構築
2. **Phase 2**: 画面1（trainとvalのアノテーション作成画面）の実装
3. **Phase 3**: 画面2（推論実行画面）の実装
4. **Phase 4**: yolov9フォルダーの整理と統合