# YOLO物体検出アプリケーション 要件定義

このプロジェクトは、YOLO（You Only Look Once）物体検出モデルのためのアノテーションと推論を行うWebアプリケーションです。

## プロジェクトの目的

YOLOモデルのアノテーションから推論までを一貫して管理できるWebアプリケーションを構築すること。

## 技術スタック

- **フレームワーク**: Django（Python Webフレームワーク）
- **機械学習**: YOLOv9モデル（物体検出用の深層学習モデル）
- **学習環境**: Google Colab（クラウドベースのJupyterノートブック環境）
- **コンテナ**: Docker（開発・本番環境の両方で使用）
- **認証**: ログイン機能は不要（認証なしでアクセス可能）

### 既存リソース

- `yolov9/` フォルダー: 動作確認済みのYOLOv9実装が含まれています
  - このフォルダー内の不要なファイルやテストファイルを整理してください

## 主な機能とワークフロー
1. データインポート機能
   - YOLO学習用の画像データセットをアプリケーションにインポート

2. アノテーション機能
   - インポートした画像に対して、物体の位置情報（バウンディングボックス）とクラスラベルを付与
   - アノテーションとは、画像内の物体に「どこに何があるか」を手動でマーキングする作業

3. データエクスポート機能
   - アノテーション済みデータセットをYOLO学習用フォーマット（YOLO形式のテキストファイルと画像のセット）でエクスポート

4. モデル学習機能
   - エクスポートしたデータセットをGoogle Colab上で使用してYOLOモデルを学習
   - 学習が完了すると、物体検出が可能な学習済みモデルファイル（.pt形式など）が生成される

5. モデルインポート機能
   - Colabで学習したモデルファイルをアプリケーションにインポート

6. 推論機能
   - インポートした学習済みモデルを使用して、新しい画像に対して物体検出の推論（予測）を実行
   - 推論結果として、検出された物体の位置とクラスが表示される

## 機能要件

### 画面1: train用のアノテーション作成画面

#### 1.1 画像インポート機能
- **方法**: ドラッグ&ドロップまたはファイル選択ダイアログ
- **対応形式**: 一般的な画像形式（jpg, png, jpeg等）
- **動作**: インポートした画像は即座に画面に表示される
- **複数選択**: 複数画像の一括インポートに対応

#### 1.2 画像表示エリア
- **配置**: メインエリア
- **機能**: 
  - インポートした画像を一覧表示（アノテーション作業がしやすい適切なサイズで表示）
  - 画像上でマウス操作による矩形描画が可能

#### 1.3 クラス管理パネル（左側）
- **配置**: 画面左側に固定サイドバー
- **機能**:
  - クラス一覧の表示
  - 「追加」ボタンで新しいクラスを追加（クラス名・色を入力）
  - クラスをクリックして選択状態にする（選択中のクラスは視覚的に区別）
  - 選択したクラスがアノテーションに適用される

#### 1.4 アノテーション機能
- **操作フロー**:
  1. 左側パネルでクラスを選択
  2. 画像上でマウスドラッグして矩形（バウンディングボックス）を描画
  3. 矩形が描画されると、選択中のクラスが自動的に割り当てられる
- **表示**: 矩形は色分けして表示（クラスごとに異なる色）
- **編集**: 既存の矩形を選択して削除または修正可能

#### 1.5 エクスポート機能
- **ボタン**: 「完了」ボタンを画面に配置
- **確認画面**: モーダルで「エクスポートしてもいいですか？」と確認し、「エクスポート」ボタンで出力開始
- **ダウンロード方法**: ブラウザのダウンロード機能を使用してダウンロード
- **保存先**: ブラウザのデフォルトダウンロードフォルダ（通常はユーザーのダウンロードフォルダ）
- **出力形式**: `train.zip` ファイルとしてダウンロード（展開すると以下の構造）
  ```
  train/
  ├── images/
  │   ├── image001.jpg
  │   ├── image002.jpg
  │   └── ...
  └── labels/
      ├── image001.txt
      ├── image002.txt
      └── ...
  ```
- **出力内容**:
  - **imagesフォルダ**: アノテーション対象の画像ファイル
  - **labelsフォルダ**: YOLO形式のテキストファイル（各画像に対応する.txtファイル）
    - **ファイル名**: `画像名.txt`（例: `image001.jpg` → `image001.txt`）
    - **フォーマット**: 正規化座標で以下の形式
      ```
      class_id center_x center_y width height
      ```

### 画面2: val用のアノテーション作成画面

画面1と同様の機能を提供しますが、エクスポート先が異なります。

#### 2.5 エクスポート機能（画面2）

- **ボタン**: 「完了」ボタンを画面に配置
- **確認画面**: モーダルで「エクスポートしてもいいですか？」と確認し、「エクスポート」ボタンで出力開始
- **ダウンロード方法**: ブラウザのダウンロード機能を使用してダウンロード
- **保存先**: ブラウザのデフォルトダウンロードフォルダ（通常はユーザーのダウンロードフォルダ）
- **出力形式**: `val.zip` ファイルとしてダウンロード（展開すると以下の構造）
  ```
  val/
  ├── images/
  │   ├── image001.jpg
  │   ├── image002.jpg
  │   └── ...
  └── labels/
      ├── image001.txt
      ├── image002.txt
      └── ...
  ```
- **出力内容**:
  - **imagesフォルダ**: アノテーション対象の画像ファイル
  - **labelsフォルダ**: YOLO形式のテキストファイル（各画像に対応する.txtファイル）
    - **ファイル名**: `画像名.txt`（例: `image001.jpg` → `image001.txt`）
    - **フォーマット**: 正規化座標で以下の形式
      ```
      class_id center_x center_y width height
      ```

### 画面3: 推論実行画面

#### 3.1 モデルインポート機能
- **対象**: Google Colabで学習した学習済み重みファイル（.pt形式）
- **方法**: ファイル選択ダイアログまたはドラッグ&ドロップ

#### 3.2 推論画像インポート機能
- **方法**: ドラッグ&ドロップまたはファイル選択ダイアログ
- **対応**: 単一画像または複数画像
- **表示**: インポートした画像をプレビュー表示

#### 3.3 推論実行機能
- **ボタン**: 「推論開始」ボタン
- **処理**:
  1. インポート済みの学習済みモデルを読み込む
  2. 推論画像に対して物体検出を実行
  3. 検出結果を画像上に描画（バウンディングボックス + クラス名 + 信頼度スコア）

#### 3.4 結果表示機能
- **表示内容**:
  - 検出された物体のバウンディングボックス
  - クラス名
  - 信頼度スコア（0.0-1.0）
- **保存**: 推論結果画像を保存できる機能

## データフロー

### アノテーション → 学習用データセット

```
画像インポート → アノテーション作成 → エクスポート
```

### 推論フロー

```
学習済みモデル(.pt)インポート → 推論画像インポート → 推論実行 → 結果表示
```

## 実装の優先順位

1. **Phase 1**: 基本的なDjangoプロジェクトセットアップ + Docker環境構築
2. **Phase 2**: 画面1（アノテーション作成画面）の実装
3. **Phase 3**: 画面2（推論実行画面）の実装
4. **Phase 4**: yolov9フォルダーの整理と統合